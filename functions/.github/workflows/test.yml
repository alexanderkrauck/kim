name: Comprehensive Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r tests/requirements-test.txt
    
    - name: Set up environment variables for testing
      env:
        APOLLO_API_KEY: ${{ secrets.APOLLO_API_KEY_TEST }}
        PERPLEXITY_API_KEY: ${{ secrets.PERPLEXITY_API_KEY_TEST }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}
      run: |
        echo "APOLLO_API_KEY=mock_apollo_key_for_testing" >> $GITHUB_ENV
        echo "PERPLEXITY_API_KEY=mock_perplexity_key_for_testing" >> $GITHUB_ENV
        echo "OPENAI_API_KEY=mock_openai_key_for_testing" >> $GITHUB_ENV
        echo "DEBUG=true" >> $GITHUB_ENV
    
    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=120 --statistics
    
    - name: Format check with black
      run: |
        black --check --diff .
      continue-on-error: true
    
    - name: Import sorting check with isort
      run: |
        isort --check-only --diff .
      continue-on-error: true
    
    - name: Run comprehensive test suite
      run: |
        python tests/run_tests.py -vv --output test-results.json
    
    - name: Run tests with pytest (alternative)
      if: failure()
      run: |
        pytest tests/ -v --cov=. --cov-report=xml --cov-report=html
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}
        path: |
          test-results.json
          htmlcov/
          coverage.xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.python-version == '3.10'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: true

  security-scan:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.10
    
    - name: Install security scanning tools
      run: |
        pip install bandit safety
    
    - name: Run Bandit security scan
      run: |
        bandit -r . -f json -o bandit-report.json
      continue-on-error: true
    
    - name: Check for known security vulnerabilities
      run: |
        safety check --json --output safety-report.json
      continue-on-error: true
    
    - name: Upload security scan results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-scan-results
        path: |
          bandit-report.json
          safety-report.json

  performance-test:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[perf-test]')
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.10
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r tests/requirements-test.txt
        pip install memory-profiler
    
    - name: Run performance tests
      run: |
        # Run performance-specific tests if they exist
        python tests/run_tests.py -p "performance" -v
      continue-on-error: true

  docs-test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.10
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install sphinx sphinx-rtd-theme
    
    - name: Test documentation build
      run: |
        # Test that documentation can be built
        python -m doctest README.md
      continue-on-error: true
    
    - name: Check for TODO and FIXME comments
      run: |
        echo "Checking for TODO and FIXME comments..."
        find . -name "*.py" -exec grep -Hn "TODO\|FIXME" {} \; > todo-list.txt || true
        if [ -s todo-list.txt ]; then
          echo "Found TODO/FIXME comments:"
          cat todo-list.txt
        else
          echo "No TODO/FIXME comments found"
        fi
    
    - name: Upload documentation artifacts
      uses: actions/upload-artifact@v3
      with:
        name: documentation-artifacts
        path: |
          todo-list.txt 